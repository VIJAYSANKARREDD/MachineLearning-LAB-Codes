{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1c2c7a7-1188-43d6-a104-601d2c33ddff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running on: C:\\Users\\asus\\Downloads\\sleep-edf-database-expanded-1.0.0\\sleep-edf-database-expanded-1.0.0\\sleep-cassette\\SC4001E0-PSG.edf ===\n",
      "Loading PSG: C:\\Users\\asus\\Downloads\\sleep-edf-database-expanded-1.0.0\\sleep-edf-database-expanded-1.0.0\\sleep-cassette\\SC4001E0-PSG.edf\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_20828\\4259536952.py:35: RuntimeWarning: Limited 1 annotation(s) that were expanding outside the data range.\n",
      "  raw.set_annotations(ann)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked channel: EEG Fpz-Cz\n",
      "Extracted epochs: 46\n",
      "Unique stages found: [2 4]\n",
      "\n",
      "[A1] Entropy: 0.5586293734521992\n",
      "[A1] Equal-width bin edges: [-3.19984371e-07 -1.02782906e-07  1.14418559e-07  3.31620024e-07\n",
      "  5.48821490e-07]\n",
      "\n",
      "[A2] Gini index: 0.22684310018903586\n",
      "\n",
      "[A3/A4] IG scores: {'mean': np.float64(0.029119529510904643), 'std': np.float64(0.17692221996479585), 'min': np.float64(0.14487213099447288), 'max': np.float64(0.16459607041091118), 'p25': np.float64(0.20464200605757776), 'p75': np.float64(0.25415435463210523)}\n",
      "Best root attribute: p75\n",
      "\n",
      "[A5] Confusion Matrix:\n",
      " [[40  0]\n",
      " [ 1  5]]\n",
      "\n",
      "[A6] Sklearn Decision Tree:\n",
      "\n",
      "[A7] Decision Boundary (mean vs std):\n",
      "Confusion Matrix:\n",
      " [[9 1]\n",
      " [2 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2      0.818     0.900     0.857        10\n",
      "           4      0.000     0.000     0.000         2\n",
      "\n",
      "    accuracy                          0.750        12\n",
      "   macro avg      0.409     0.450     0.429        12\n",
      "weighted avg      0.682     0.750     0.714        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lab06 A1-A7 — Modularized functions using Sleep-EDF Expanded dataset\n",
    "# Always prints outputs: falls back to all stages if N2/REM not found\n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log2\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ---------------------------\n",
    "# USER SETTINGS\n",
    "# ---------------------------\n",
    "DATA_PATH = r\"C:\\Users\\asus\\Downloads\\sleep-edf-database-expanded-1.0.0\"\n",
    "PREFERRED_CHANNELS = [\"EEG Fpz-Cz\", \"Fpz-Cz\", \"EEG Pz-Oz\", \"Pz-Oz\"]\n",
    "ENABLE_PLOTS = False        # Set True to see plots\n",
    "CROP_SECONDS = None         # None = use full night, or set seconds (e.g. 7200)\n",
    "\n",
    "# ---------------------------\n",
    "# Utilities\n",
    "# ---------------------------\n",
    "def load_raw(psg_file, hyp_file=None, verbose=True):\n",
    "    \"\"\"Load PSG EDF file + hypnogram annotations.\"\"\"\n",
    "    if verbose:\n",
    "        print(\"Loading PSG:\", psg_file)\n",
    "    raw = mne.io.read_raw_edf(psg_file, preload=True, stim_channel=None, verbose=\"ERROR\")\n",
    "    if CROP_SECONDS:\n",
    "        raw.crop(tmin=0, tmax=CROP_SECONDS)\n",
    "    if hyp_file and os.path.exists(hyp_file):\n",
    "        ann = mne.read_annotations(hyp_file)\n",
    "        raw.set_annotations(ann)\n",
    "    return raw\n",
    "\n",
    "def pick_best_channel(raw, preferred=PREFERRED_CHANNELS):\n",
    "    \"\"\"Pick EEG channel (prefer Fpz-Cz or Pz-Oz).\"\"\"\n",
    "    for p in preferred:\n",
    "        if p in raw.ch_names:\n",
    "            raw.pick_channels([p])\n",
    "            return p\n",
    "    for ch in raw.ch_names:\n",
    "        if \"EEG\" in ch or \"Fpz\" in ch or \"Pz\" in ch:\n",
    "            raw.pick_channels([ch])\n",
    "            return ch\n",
    "    raw.pick_channels([raw.ch_names[0]])\n",
    "    return raw.ch_names[0]\n",
    "\n",
    "def extract_epoch_features(raw, keep_stages=(2, 4), epoch_sec=30, max_epochs=None):\n",
    "    \"\"\"Extract epochs and compute features. Falls back if N2/REM not found.\"\"\"\n",
    "    mapping = {\n",
    "        \"Sleep stage W\": 0, \"Sleep stage 1\": 1, \"Sleep stage 2\": 2,\n",
    "        \"Sleep stage 3\": 3, \"Sleep stage 4\": 3, \"Sleep stage R\": 4,\n",
    "        \"W\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 3, \"R\": 4\n",
    "    }\n",
    "    sfreq = int(raw.info[\"sfreq\"])\n",
    "    sig = raw.get_data()[0]\n",
    "    features, labels = [], []\n",
    "\n",
    "    for i, ann in enumerate(raw.annotations):\n",
    "        if max_epochs and i >= max_epochs:\n",
    "            break\n",
    "        desc = ann[\"description\"]\n",
    "        lab = mapping.get(desc, -1)\n",
    "        if lab == -1:\n",
    "            continue\n",
    "        if keep_stages and lab not in keep_stages:\n",
    "            continue\n",
    "        start = int(ann[\"onset\"] * sfreq)\n",
    "        end = start + epoch_sec * sfreq\n",
    "        if end > len(sig):\n",
    "            continue\n",
    "        seg = sig[start:end]\n",
    "        feats = [np.mean(seg), np.std(seg), np.min(seg),\n",
    "                 np.max(seg), np.percentile(seg, 25), np.percentile(seg, 75)]\n",
    "        features.append(feats)\n",
    "        labels.append(lab)\n",
    "\n",
    "    df = pd.DataFrame(features, columns=[\"mean\", \"std\", \"min\", \"max\", \"p25\", \"p75\"])\n",
    "    df[\"stage\"] = labels\n",
    "    return df\n",
    "\n",
    "# ---------------------------\n",
    "# A1: Entropy + Binning\n",
    "# ---------------------------\n",
    "def entropy(labels):\n",
    "    counts = Counter(labels)\n",
    "    n = sum(counts.values())\n",
    "    return -sum((c/n)*log2(c/n) for c in counts.values() if c > 0)\n",
    "\n",
    "def equal_width_binning(x, n_bins=4):\n",
    "    edges = np.linspace(x.min(), x.max(), n_bins + 1)\n",
    "    codes = np.digitize(x, edges[1:-1])\n",
    "    return codes, edges\n",
    "\n",
    "def equal_freq_binning(x, n_bins=4):\n",
    "    edges = np.unique(np.quantile(x, np.linspace(0, 1, n_bins + 1)))\n",
    "    codes = np.digitize(x, edges[1:-1])\n",
    "    return codes, edges\n",
    "\n",
    "# ---------------------------\n",
    "# A2: Gini Index\n",
    "# ---------------------------\n",
    "def gini_index(labels):\n",
    "    counts = Counter(labels)\n",
    "    n = sum(counts.values())\n",
    "    return 1 - sum((c/n)**2 for c in counts.values())\n",
    "\n",
    "# ---------------------------\n",
    "# A3/A4: Information Gain + Root Attribute\n",
    "# ---------------------------\n",
    "def information_gain(y, x_cat):\n",
    "    H_y = entropy(y)\n",
    "    n = len(y)\n",
    "    ig = H_y\n",
    "    for v in np.unique(x_cat):\n",
    "        mask = (x_cat == v)\n",
    "        ig -= (np.sum(mask)/n) * entropy(np.array(y)[mask])\n",
    "    return ig\n",
    "\n",
    "def choose_root_attribute(X_df, y, binning=\"width\", n_bins=4):\n",
    "    ig_scores, binned = {}, pd.DataFrame(index=X_df.index)\n",
    "    for col in X_df.columns:\n",
    "        if binning == \"freq\":\n",
    "            codes, _ = equal_freq_binning(X_df[col].values, n_bins)\n",
    "        else:\n",
    "            codes, _ = equal_width_binning(X_df[col].values, n_bins)\n",
    "        binned[col] = codes\n",
    "        ig_scores[col] = information_gain(y, codes)\n",
    "    best = max(ig_scores, key=ig_scores.get)\n",
    "    return best, ig_scores, binned\n",
    "\n",
    "# ---------------------------\n",
    "# A5: ID3 Tree\n",
    "# ---------------------------\n",
    "class SimpleDTNode:\n",
    "    def __init__(self, depth=0):\n",
    "        self.depth, self.is_leaf, self.pred = depth, False, None\n",
    "        self.split_feature, self.children = None, {}\n",
    "\n",
    "def build_id3_tree(X_binned, y, max_depth=5):\n",
    "    def build(X, y, depth):\n",
    "        node = SimpleDTNode(depth)\n",
    "        if len(set(y)) == 1 or depth >= max_depth:\n",
    "            node.is_leaf, node.pred = True, Counter(y).most_common(1)[0][0]\n",
    "            return node\n",
    "        best_feat = max(X.columns, key=lambda c: information_gain(y, X[c].values))\n",
    "        node.split_feature = best_feat\n",
    "        for val in np.unique(X[best_feat]):\n",
    "            mask = X[best_feat] == val\n",
    "            child = build(X.loc[mask].drop(columns=[best_feat]), np.array(y)[mask], depth+1)\n",
    "            node.children[val] = child\n",
    "        return node\n",
    "    return build(X_binned, y, 0)\n",
    "\n",
    "def predict_id3_batch(root, X_binned):\n",
    "    preds = []\n",
    "    for _, row in X_binned.iterrows():\n",
    "        node = root\n",
    "        while not node.is_leaf:\n",
    "            val = row[node.split_feature]\n",
    "            node = node.children.get(val, node)\n",
    "        preds.append(node.pred if node.pred is not None else 0)\n",
    "    return np.array(preds)\n",
    "\n",
    "# ---------------------------\n",
    "# A6: Sklearn Tree Visualization\n",
    "# ---------------------------\n",
    "def sklearn_tree_visualization(X_binned, y):\n",
    "    clf = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    clf.fit(X_binned, y)\n",
    "    if ENABLE_PLOTS:\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plot_tree(clf, feature_names=X_binned.columns, filled=True)\n",
    "        plt.show()\n",
    "    return clf\n",
    "\n",
    "# ---------------------------\n",
    "# A7: Decision Boundary\n",
    "# ---------------------------\n",
    "def plot_decision_boundary_two_features(X_df, y, featA, featB):\n",
    "    X = X_df[[featA, featB]].values\n",
    "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "    clf = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    if ENABLE_PLOTS:\n",
    "        x_min, x_max = X[:,0].min(), X[:,0].max()\n",
    "        y_min, y_max = X[:,1].min(), X[:,1].max()\n",
    "        xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "        plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "        plt.scatter(Xtr[:,0], Xtr[:,1], c=ytr, label=\"Train\", edgecolor=\"k\")\n",
    "        plt.scatter(Xte[:,0], Xte[:,1], c=yte, marker=\"^\", s=60, label=\"Test\", edgecolor=\"k\")\n",
    "        plt.xlabel(featA); plt.ylabel(featB); plt.legend(); plt.show()\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(yte, clf.predict(Xte)))\n",
    "    print(classification_report(yte, clf.predict(Xte), digits=3))\n",
    "\n",
    "# ---------------------------\n",
    "# Main run for one file\n",
    "# ---------------------------\n",
    "def main_run(psg_file, hyp_file):\n",
    "    raw = load_raw(psg_file, hyp_file)\n",
    "    ch = pick_best_channel(raw)\n",
    "    print(\"Picked channel:\", ch)\n",
    "\n",
    "    # Try N2 vs REM\n",
    "    df = extract_epoch_features(raw, keep_stages=(2,4))\n",
    "    if df.shape[0] == 0:\n",
    "        print(\"⚠️ No N2/REM found. Falling back to all stages.\")\n",
    "        df = extract_epoch_features(raw, keep_stages=None)\n",
    "\n",
    "    print(\"Extracted epochs:\", df.shape[0])\n",
    "    print(\"Unique stages found:\", df[\"stage\"].unique())\n",
    "    if df.shape[0] == 0:\n",
    "        print(\"❌ Still no usable epochs. Skipping file.\")\n",
    "        return\n",
    "\n",
    "    # A1\n",
    "    print(\"\\n[A1] Entropy:\", entropy(df[\"stage\"]))\n",
    "    codes_w, edges_w = equal_width_binning(df[\"mean\"].values)\n",
    "    print(\"[A1] Equal-width bin edges:\", edges_w)\n",
    "\n",
    "    # A2\n",
    "    print(\"\\n[A2] Gini index:\", gini_index(df[\"stage\"]))\n",
    "\n",
    "    # A3/A4\n",
    "    best, ig_scores, binned = choose_root_attribute(df.drop(columns=[\"stage\"]), df[\"stage\"])\n",
    "    print(\"\\n[A3/A4] IG scores:\", ig_scores)\n",
    "    print(\"Best root attribute:\", best)\n",
    "\n",
    "    # A5\n",
    "    tree = build_id3_tree(binned, df[\"stage\"])\n",
    "    preds = predict_id3_batch(tree, binned)\n",
    "    print(\"\\n[A5] Confusion Matrix:\\n\", confusion_matrix(df[\"stage\"], preds))\n",
    "\n",
    "    # A6\n",
    "    print(\"\\n[A6] Sklearn Decision Tree:\")\n",
    "    sklearn_tree_visualization(binned, df[\"stage\"])\n",
    "\n",
    "    # A7\n",
    "    print(\"\\n[A7] Decision Boundary (mean vs std):\")\n",
    "    plot_decision_boundary_two_features(df, df[\"stage\"], \"mean\", \"std\")\n",
    "\n",
    "# ---------------------------\n",
    "# Loop through dataset\n",
    "# ---------------------------\n",
    "def run_on_dataset(data_path, max_files=1):\n",
    "    count = 0\n",
    "    for root, _, files in os.walk(data_path):\n",
    "        for f in files:\n",
    "            if f.endswith(\"-PSG.edf\"):\n",
    "                psg = os.path.join(root, f)\n",
    "                hyp = None\n",
    "                for g in files:\n",
    "                    if \"hyp\" in g.lower():\n",
    "                        hyp = os.path.join(root, g)\n",
    "                        break\n",
    "                print(\"\\n=== Running on:\", psg, \"===\")\n",
    "                main_run(psg, hyp)\n",
    "                count += 1\n",
    "                if max_files and count >= max_files:\n",
    "                    return\n",
    "\n",
    "# ---------------------------\n",
    "# Run\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    run_on_dataset(DATA_PATH, max_files=1)   # change to None for all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6cffc2-f5ce-451f-9b5d-ded8e36e190f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
